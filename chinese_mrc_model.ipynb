{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Cn-gQTGhC7z"
   },
   "source": [
    "# BERT fine tune DRCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uubPXZfugyLD",
    "outputId": "a13176bc-25cd-4e8b-c079-ee9e7b8ad9d2"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from transformers import *\n",
    "import pandas as pd\n",
    "import ast\n",
    "import copy\n",
    "import os\n",
    "import json\n",
    "from time import strftime,gmtime\n",
    "from opencc import OpenCC\n",
    "import pyprind\n",
    "from sklearn.utils import shuffle\n",
    "import re\n",
    "from zhon.hanzi import non_stops, stops\n",
    "import numpy as np\n",
    "import random\n",
    "import argparse\n",
    "import time\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class DRCDRawData():\n",
    "    def __init__(self, train_path=None , test_path=None ,dev_path=None):\n",
    "        if train_path != None:\n",
    "            self.train = self.load_data(train_path)\n",
    "        if test_path != None:\n",
    "            self.test = self.load_data(test_path)\n",
    "        if dev_path != None:\n",
    "            self.dev = self.load_data(dev_path)\n",
    "    def load_data(self,path):\n",
    "        dataset = json.load(open(path, encoding='utf-8'))\n",
    "        result = []\n",
    "        for i in range(len(dataset['data'])):\n",
    "            for j in dataset['data'][i]['paragraphs']:\n",
    "                context = j['context']\n",
    "                for qa in j['qas']:\n",
    "                    question = qa['question']\n",
    "                    if qa['answers']:\n",
    "                        result.append([context,question,qa['answers'][0]])                     \n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7P7DpSVMcy7Y"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kFAFURdNcP77"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class DRCD(Dataset):\n",
    "    def __init__(self, data, model_type, device, language):\n",
    "        self.data = data\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model_type)\n",
    "        self.device = device\n",
    "        self.cc = OpenCC('t2s') # tw->china\n",
    "        self.language = language\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        paragraph, question, ans = self.data[idx][0], self.data[idx][1], self.data[idx][2] \n",
    "        \n",
    "        if self.language == 'china':\n",
    "            paragraph, question, ans = self.cc.convert(paragraph), self.cc.convert(question), self.cc.convert(ans)\n",
    "        \n",
    "        # Tokenize and prepare for the model a sequence or a pair of sequences. \n",
    "        # so unlike 'encode' just encode to ids, encode_plus return not only ids \n",
    "        # but token_type_ids, attention_mask also\n",
    "        token_tensor = self.tokenizer.encode_plus(question, paragraph, max_length=512, \n",
    "                                                  truncation=True, pad_to_max_length=True)\n",
    "        \n",
    "        ans_encode = self.tokenizer.encode(ans)\n",
    "        s_tensor, e_tensor = self.find_ans_index(token_tensor, ans_encode)\n",
    "\n",
    "        return {'input_ids': torch.tensor(token_tensor['input_ids']).to(self.device),\n",
    "                'token_type_ids': torch.tensor(token_tensor['token_type_ids']).to(self.device),\n",
    "                'attention_mask': torch.tensor(token_tensor['attention_mask']).to(self.device),\n",
    "                's_tensor': s_tensor.to(self.device),\n",
    "                'e_tensor': e_tensor.to(self.device)}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def find_ans_index(self, token_tensor, ans_encode):\n",
    "        s_idx, e_idx = [0] * 512, [0] * 512\n",
    "\n",
    "        # answer's token (removing [CLS] and [SEP] by [1:-1])\n",
    "        s_tok = self.tokenizer.encode(ans)[1:-1]\n",
    "        \n",
    "        # find the idx of paragraph startwith ans's first token \n",
    "        s_list = [i for i, x in enumerate(token_tensor['input_ids']) if x == s_tok[0]]\n",
    "      \n",
    "        for s_pos in s_list:\n",
    "            e_pos = s_pos + len(s_tok)\n",
    "            if e_pos > 511:\n",
    "                continue\n",
    "            if token_tensor['input_ids'][s_pos:e_pos] == s_tok:\n",
    "                s_idx[s_pos] = 1\n",
    "                e_idx[e_pos-1] = 1\n",
    "                break\n",
    "        return  torch.Tensor(s_idx), torch.Tensor(e_idx)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Z-zDS64xoOO"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForReadingComprehension(nn.Module):\n",
    "    def __init__(self, model_type):\n",
    "        super(BertForReadingComprehension, self).__init__()\n",
    "\n",
    "        config = BertConfig.from_pretrained(model_type, output_hidden_states=True)\n",
    "        self.bert_model = BertModel.from_pretrained(model_type, config=config)\n",
    "        \n",
    "        self.s_decoder = nn.Sequential(nn.Linear(config.hidden_size, 1)) \n",
    "        self.e_decoder = nn.Sequential(nn.Linear(config.hidden_size, 1))\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None): \n",
    "        hidden = self.bert_model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)[0]\n",
    "        \n",
    "        s = self.s_decoder(hidden).squeeze()\n",
    "        e = self.e_decoder(hidden).squeeze()\n",
    "        \n",
    "        # mask question part, because ans only appear in paragraph.\n",
    "        mask = token_type_ids.clone().float().to(hidden.device).detach()\n",
    "        mask[mask != 1] = float('-inf')\n",
    "\n",
    "        return s + mask, e + mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2tNzN6c-xZ_A"
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-YduImGhxb6q"
   },
   "outputs": [],
   "source": [
    "def test(model, ds, args, tp):\n",
    "    if tp == 'test':\n",
    "        dataset = DRCD(ds.test, args.model_type, args.device, args.language)\n",
    "        print(f'Testing...{len(dataset)}')\n",
    "    elif tp == 'dev':   \n",
    "        dataset = DRCD(ds.dev, args.model_type, args.device, args.language)\n",
    "        print(f'Dev...{len(dataset)}')\n",
    "    loader = DataLoader(dataset, batch_size=args.batch_size, shuffle=True)\n",
    "    model.eval()\n",
    "    loss,i = 0,0\n",
    "    print(loss,i)\n",
    "    criterion = nn.BCELoss()\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            i = i+1\n",
    "            inp_ids, tok_id, att_m, slabel, elabel = batch['input_ids'], batch['token_type_ids'], batch['attention_mask'], batch['s_tensor'], batch['e_tensor']\n",
    "            s, e = model(input_ids=inp_ids,attention_mask=att_m,token_type_ids=tok_id)\n",
    "            #print(f's {s} \\n e {e} \\n sl {torch.softmax(s,dim=-1)} \\n el {torch.softmax(e,dim=-1)} \\n ')\n",
    "            #print(f'SL {slabel} \\n EL {elabel}')\n",
    "            batch_loss = (criterion(torch.softmax(s,dim=-1),slabel) + criterion(torch.softmax(e,dim=-1),elabel)) / 2\n",
    "            loss += batch_loss\n",
    "            \n",
    "        print(f'Result: LOSS: {loss} AVG: {loss/i} ')\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EGbz1SUhxcb2"
   },
   "outputs": [],
   "source": [
    "def train(ds,args):\n",
    "    dataset = DRCD(ds.train, args.model_type, args.device, args.language)\n",
    "    trainLoader = DataLoader(dataset, batch_size=args.batch_size, shuffle=True)\n",
    "    model = BertForReadingComprehension(args.model_type).to(args.device)\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = AdamW(parameters, lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "    criterion = nn.BCELoss()\n",
    "    model.train()\n",
    "    minloss = 100000\n",
    "    for ei in range(args.epoch):\n",
    "        model.train()\n",
    "        epoch_loss,i,check_loss = 0,0,0\n",
    "        for batch in trainLoader:\n",
    "            i+=1\n",
    "            inp_ids,tok_id,att_m ,slabel,elabel = batch['input_ids'],batch['token_type_ids'],batch['attention_mask'],batch['s_tensor'],batch['e_tensor']\n",
    "            s,e = model(input_ids=inp_ids,attention_mask=att_m,token_type_ids=tok_id)\n",
    "            #print(f's {s} \\n e {e} \\n sl {torch.softmax(s,dim=-1)} \\n el {torch.softmax(e,dim=-1)} \\n ')\n",
    "            #print(f'SL {slabel} \\n EL {elabel}')\n",
    "            batch_loss = (criterion(torch.softmax(s,dim=-1),slabel) + criterion(torch.softmax(e,dim=-1),elabel)) / 2\n",
    "            epoch_loss += batch_loss\n",
    "            check_loss += batch_loss\n",
    "            #print(batch_loss)\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            if i % 1000==0:\n",
    "                print(f'1000 batch LOSS {check_loss}')\n",
    "                check_loss = 0\n",
    "        dev_loss = test(model,ds,args, 'dev') \n",
    "        if dev_loss < minloss:\n",
    "            minloss = dev_loss\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "        print(f'===Epoches: {ei} Loss {epoch_loss}===')       \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "llu-ld14gYdA"
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "x8P9_YXsgaCT",
    "outputId": "b0d26f7b-3f4a-4300-f0a8-0feb6d9e9874"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Quadro P2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Namespace(batch_size=2, device=device(type='cuda', index=0), epoch=5, language='tw', learning_rate=1e-05, model_type='hfl/chinese-roberta-wwm-ext', weight_decay=0.001)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "parser = argparse.ArgumentParser([])\n",
    "parser.add_argument('--batch-size', default=2 , type=int)\n",
    "parser.add_argument('--epoch', default=5, type=int)\n",
    "parser.add_argument('--learning-rate', default=1e-5, type=float)    \n",
    "parser.add_argument('--weight-decay', default=0.001, type=float)\n",
    "parser.add_argument('--model-type', default='hfl/chinese-roberta-wwm-ext' , type=str)  #model_type = 'hfl/chinese-bert-wwm'  'hfl/chinese-roberta-wwm-ext'  'hfl/chinese-roberta-wwm-ext-large'\n",
    "parser.add_argument('--device', default=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu'), type=int)\n",
    "parser.add_argument('--language', default='tw', type=str)\n",
    "args = parser.parse_args([])\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ac4TkXWchw4L"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2010年引進的廣州快速公交運輸系統，屬世界第二大快速公交系統，日常載客量可達100萬人次，高峰時期每小時單向客流高達26900人次，僅次於波哥大的快速交通系統，平均每10秒鐘就有一輛巴士，每輛巴士單向行駛350小時。包括橋樑在內的站台是世界最長的州快速公交運輸系統站台，長達260米。目前廣州市區的計程車和公共汽車主要使用液化石油氣作燃料，部分公共汽車更使用油電、氣電混合動力技術。2012年底開始投放液化天然氣燃料的公共汽車，2014年6月開始投放液化天然氣插電式混合動力公共汽車，以取代液化石油氣公共汽車。2007年1月16日，廣州市政府全面禁止在市區內駕駛摩托車。違反禁令的機動車將會予以沒收。廣州市交通局聲稱禁令的施行，使得交通擁擠問題和車禍大幅減少。廣州白雲國際機場位於白雲區與花都區交界，2004年8月5日正式投入運營，屬中國交通情況第二繁忙的機場。該機場取代了原先位於市中心的無法滿足日益增長航空需求的舊機場。目前機場有三條飛機跑道，成為國內第三個擁有三跑道的民航機場。比鄰近的香港國際機場第三跑道預計的2023年落成早8年。',\n",
       " '廣州的快速公交運輸系統每多久就會有一輛巴士？',\n",
       " {'id': '1', 'text': '10秒鐘', 'answer_start': 84}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = DRCDRawData(train_path='./dataset/DRCD_train.json',\n",
    "                   test_path='./dataset/DRCD_test.json',\n",
    "                   dev_path='./dataset/DRCD_dev.json')\n",
    "data.train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "id": "bEyDq_PC1i82",
    "outputId": "6e6dafc9-e7b0-408f-8b80-337644122cc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    376\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Python 2.7, use buffering of HTTP responses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 377\u001b[1;33m                 \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    378\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Python 2.6 and older, Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: getresponse() got an unexpected keyword argument 'buffering'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-83a6955bd6ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mbest_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'saved_models'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'saved_models'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-91318643b016>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(ds, args)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDRCD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtrainLoader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertForReadingComprehension\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAdamW\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-a0fccfbd7065>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model_type)\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBertForReadingComprehension\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertConfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbert_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m         \"\"\"\n\u001b[1;32m--> 315\u001b[1;33m         \u001b[0mconfig_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    353\u001b[0m                 \u001b[0mproxies\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m                 \u001b[0mresume_download\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_download\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m                 \u001b[0mlocal_files_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m             )\n\u001b[0;32m    357\u001b[0m             \u001b[1;31m# Load config dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\transformers\\file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[1;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, local_files_only)\u001b[0m\n\u001b[0;32m    721\u001b[0m             \u001b[0mresume_download\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_download\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m             \u001b[0muser_agent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muser_agent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 723\u001b[1;33m             \u001b[0mlocal_files_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    724\u001b[0m         )\n\u001b[0;32m    725\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\transformers\\file_utils.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[1;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, local_files_only)\u001b[0m\n\u001b[0;32m    828\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlocal_files_only\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    829\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 830\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_redirects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    831\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[0metag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ETag\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mhead\u001b[1;34m(url, **kwargs)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'head'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    528\u001b[0m         }\n\u001b[0;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 643\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    447\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m                     \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m                 )\n\u001b[0;32m    451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    598\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m                                                   chunked=chunked)\n\u001b[0m\u001b[0;32m    601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m             \u001b[1;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    378\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Python 2.6 and older, Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m                     \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m                     \u001b[1;31m# Remove the TypeError from the exception chain in Python 3;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1334\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1335\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1336\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1337\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1338\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    304\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    307\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"status line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1069\u001b[0m                   \u001b[1;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m                   self.__class__)\n\u001b[1;32m-> 1071\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1072\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1073\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m    927\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 929\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    930\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mode = 'train'\n",
    "\n",
    "if mode == 'train': \n",
    "    print('Train')\n",
    "    best_model = train(data,args)\n",
    "    if not os.path.exists('saved_models'):\n",
    "        os.makedirs('saved_models')    \n",
    "    model_name = 'BertForReadingComprehension'+'_'+(datetime.now()+timedelta(hours=8)).strftime(\"%m%d_%H%M\")+'.pt' \n",
    "    torch.save(best_model, f'saved_models/{model_name}')\n",
    "    print(f'Train end, model name is {model_name}')\n",
    "\n",
    "elif mode == 'test' or mode == 'dev':\n",
    "    model_name = 'bertDRCD_0808_1213.pt'\n",
    "    test_model = BertForReadingComprehension(args.model_type).to(args.device)\n",
    "    test_model.load_state_dict(torch.load(f'saved_models/{model_name}'))\n",
    "    test(test_model, data, args, mode)\n",
    "\n",
    "#22.53021812438965\n",
    "#22.579822540283203\n",
    "# Result: LOSS: 3.2912609577178955 AVG: 0.003765744622796774 \n",
    "# Result: LOSS: 3.526034116744995 AVG: 0.004002308938652277 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N7n5HS36ex16"
   },
   "source": [
    "# Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SVfxojHYfKJT"
   },
   "outputs": [],
   "source": [
    "class InferenceModel():\n",
    "    def __init__(self, model_path, model_type, language): \n",
    "        # device\n",
    "        # language define the language model wanna eat\n",
    "        self.device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "        # self.device = torch.device('cpu')\n",
    "        # model & tokenizer\n",
    "        # model_type = 'hfl/chinese-roberta-wwm-ext'\n",
    "        config = BertConfig.from_pretrained(model_type,output_hidden_states=True)\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model_type)\n",
    "        self.model = BertForReadingComprehension(model_type).to(self.device)\n",
    "        self.model.load_state_dict(torch.load(model_path)) \n",
    "        self.language = language\n",
    "\n",
    "        self.c2tw = OpenCC('s2t') # china to tw\n",
    "        self.tw2c = OpenCC('t2s') # tw to china\n",
    "\n",
    "    def inference(self,content,question):\n",
    "        \n",
    "        content, question = self.clean_str(content, question)\n",
    "        \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            token_tensor = self.tokenizer.encode_plus(str(question), str(content), max_length=512, \n",
    "                                                      truncation=True, pad_to_max_length=True)\n",
    "            token = torch.tensor(token_tensor['input_ids']).unsqueeze(0).to(self.device)\n",
    "            segment = torch.tensor( token_tensor['token_type_ids']).unsqueeze(0).to(self.device)\n",
    "            mask = torch.tensor( token_tensor['attention_mask'] ).unsqueeze(0).to(self.device)\n",
    "            answer_start, answer_end = self.model(input_ids=token,attention_mask=mask,token_type_ids=segment) \n",
    "      \n",
    "            # get ans\n",
    "            tokens = self.tokenizer.convert_ids_to_tokens(token.squeeze())\n",
    "            answer_start = answer_start.argmax(1)\n",
    "            answer_end = answer_end.argmax(1)\n",
    "            #print(answer_start,answer_end)\n",
    "            if answer_start > answer_end :\n",
    "                return '抱歉 這題有點難耶'\n",
    "            \n",
    "            #print(answer_start,answer_end)\n",
    "            answer = ''.join(tokens[answer_start:answer_end+1])\n",
    "            if self.language == 'tw':\n",
    "                answer = self.c2tw.convert(answer)\n",
    "            \n",
    "            \n",
    "        \n",
    "        return answer\n",
    "    \n",
    "    def clean_str(self,content,question):\n",
    "        content = content.replace(' ','')\n",
    "        question = question.replace(' ','')\n",
    "        if self.language == 'china':\n",
    "            content = self.tw2c.convert(content)\n",
    "            question = self.tw2c.convert(question)\n",
    "\n",
    "        return content,question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "76m8dUy1ew9t",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "model_name = 'bertDRCD_1023_1619.pkl'\n",
    "drcd_model = InferenceModel(f'saved_models/{model_name}','hfl/chinese-roberta-wwm-ext','tw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "蒂埃里·亨利是誰:  前法國足球運動員\n",
      "蒂埃里·亨利為法國隊出場幾次:  123次\n",
      "亨利曾在國際比賽中上演過帽子戲法嗎?:  從未\n",
      "蒂埃里·亨利是誰在哪年歐洲國家盃外圍賽中曾單場上演大四喜?:  2004年\n",
      "亨利在熱身賽中共打進多少球?:  16球\n"
     ]
    }
   ],
   "source": [
    "content = \\\n",
    "'蒂埃里·亨利是前法國足球運動員。在他職業生涯參加的國際賽事中，他為法國隊出場123次，\\\n",
    "打進51球。他的首個國際比賽進球是在1998年世界盃對陣南非的比賽中。截至2015年10月，他是法國隊的頭號射手\\\n",
    "。2007年10月，他在對陣立陶宛的比賽中打進兩球，打破了米歇爾·普拉蒂尼42球的法國隊進球紀錄。亨利於2010年7月正式退役\\\n",
    "。亨利在2009年10月對奧地利的比賽中打進了個人國家隊第51粒進球，這也是他的最後一粒進球\\\n",
    "。亨利從未在國際比賽中上演過帽子戲法，儘管他曾7次在單場比賽梅開二度。\\\n",
    "他在對陣馬爾他的比賽中進球最多，在2004年歐洲國家盃外圍賽中曾單場上演大四喜。\\\n",
    "亨利一半以上的進球來自於主場比賽，他的51個進球中有31個是在法國本土打進，\\\n",
    "其中有20個在法蘭西體育場。亨利在熱身賽中共打進16球。在2003年國際足總洲際國家盃上\\\n",
    "，亨利打進四球並榮膺最佳射手，他也因此被評為「賽事最傑出球員」。\\\n",
    "亨利在歐洲國家盃外圍賽中打入12球，其中在2004年歐洲杯外圍賽打進6球，他最終排在射手榜第三位。'\n",
    "\n",
    "question = ['蒂埃里·亨利是誰','蒂埃里·亨利為法國隊出場幾次','亨利曾在國際比賽中上演過帽子戲法嗎?',\n",
    "            '蒂埃里·亨利是誰在哪年歐洲國家盃外圍賽中曾單場上演大四喜?','亨利在熱身賽中共打進多少球?']\n",
    "\n",
    "for q in question:\n",
    "    print(q + ':  '+ drcd_model.inference(content,q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "罷免韓國瑜第二階段有通過嗎:  2020年\n",
      "中華民國選舉史上首位被罷免成功的縣市首長是誰:  韓國瑜\n",
      "罷免有效聯署書達到多少?:  37.7萬\n",
      "韓國瑜在哪天正式解職:  6月12日\n",
      "韓國瑜幾歲被轉入放牛班:  國中三年級\n",
      "韓國瑜每天上課一直看誰小腿:  前排女同學\n",
      "韓國瑜的碩士論文名稱?:  《從中共「對臺統戰」策略看兩航談判》\n",
      "韓國瑜退伍前一年考上什麼:  東吳大學英國語文學系\n",
      "韓國瑜為什麼成績一落千丈:  青春期懵懂\n",
      "韓國瑜擔任誰的助理:  馮定國\n",
      "韓國瑜喜歡什麼?:  兩航談判\n"
     ]
    }
   ],
   "source": [
    "content = '2020年4月17日，高雄市選舉委員會公告罷免有效聯署書達到37.7萬，罷韓第二階段通過\\\n",
    "，韓國瑜成為全國第一位被罷免投票兩次者、也成為首個市長罷免案進入投票階段的市長。2020年6月6日\\\n",
    "，罷免投票通過，6月12日中央選舉委員會公告結果後正式解職\\\n",
    "，韓國瑜成為中華民國選舉史上首位被罷免成功的縣市首長。\\\n",
    "韓國瑜曾自述，他在年少求學階段考試都考第一名，但國中二年級開始因青春期懵懂，\\\n",
    "每天上課一直看前排女同學的小腿，成績一落千丈，國中三年級被轉入放牛班，逃學翹課\\\n",
    "、打撞球、打架也樣樣俱全，最後在父母決定下，18歲時入中華民國陸軍軍官學校專修學生班40期\\\n",
    "，軍銜升至上尉，自稱在軍中受一位國立臺灣大學醫學系畢業的預官轉魔術方塊的啟發，感到自己的不足\\\n",
    "，決定重拾課本。退伍前一年考上東吳大學英國語文學系，\\\n",
    "畢業後又考取國立政治大學東亞研究所和淡江大學國際事務與戰略研究所。\\\n",
    "由於政大免學費還發獎學金故選擇政大東亞所就讀。就讀期間擔任臺北市議員馮定國的助理，\\\n",
    "畢業後獲法學碩士學位。碩士論文名稱為《從中共「對臺統戰」策略看兩航談判》，指導教授為蘇起。韓國瑜喜歡'\n",
    "\n",
    "question = ['罷免韓國瑜第二階段有通過嗎','中華民國選舉史上首位被罷免成功的縣市首長是誰'\n",
    "            ,'罷免有效聯署書達到多少?','韓國瑜在哪天正式解職','韓國瑜幾歲被轉入放牛班'\n",
    "            ,'韓國瑜每天上課一直看誰小腿','韓國瑜的碩士論文名稱?',\n",
    "            '韓國瑜退伍前一年考上什麼','韓國瑜為什麼成績一落千丈','韓國瑜擔任誰的助理', '韓國瑜喜歡什麼?']\n",
    "\n",
    "for q in question:\n",
    "    print(q + ':  '+ drcd_model.inference(content,q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeXT公司是誰創造的:  賈伯斯\n",
      "NeXT公司是在哪年成立:  1985年\n",
      "誰決議買下NeXT公司:  蘋果公司另一始創人史蒂夫·沃茲尼克及首任投資者邁克·馬庫拉協同其他人設計、開發及銷售apple##ii系列。在1980年代初，賈伯斯是最早看到全錄帕洛奧圖中心（x##er##ox##pa##rc）的滑鼠驅動圖形用戶介面的商業潛力，並將其應用於apple##lis##a及一年後的麥金塔電腦。1985年，在董事會\n",
      "誰成立了皮克斯:  賈伯斯\n",
      "誰是《玩具總動員》的執行製片人:  賈伯斯\n",
      "皮克斯動畫在哪年被華特迪士尼公司收購:  2006年\n"
     ]
    }
   ],
   "source": [
    "content = '賈伯斯在1970年代末與蘋果公司另一始創人史蒂夫·沃茲尼克及首任投資者邁克·馬庫拉協同其他人設計、\\\n",
    "開發及銷售Apple II系列。在1980年代初，賈伯斯是最早看到全錄帕洛奧圖中心（Xerox PARC）的滑鼠驅動圖形用戶介面的商業潛力，\\\n",
    "並將其應用於Apple Lisa及一年後的麥金塔電腦。1985年，在董事會的鬥爭失勢後，賈伯斯離開蘋果公司及成立了NeXT公司(一間電腦\\\n",
    "平台開發公司，專門從事高等教育及商業市場)在1986年，他收購了盧卡斯影業的電腦繪圖部門，成立了皮克斯（Pixar）。\\\n",
    "他被譽為《玩具總動員》（1995年）的執行製片人。他一直擔任皮克斯動畫的執行長並持有50.1%的股份，\\\n",
    "直到公司在2006年被華特迪士尼公司收購，此項收購使賈伯斯成為迪士尼公司的最大個人股東（有7.4%的股份）及董事會成員。\\\n",
    "在1996年，蘋果公司董事會決議買下NeXT公司，把賈伯斯帶回他參與創立，卻正在垂死邊緣的蘋果公司擔任臨時CEO。\\\n",
    "他在2000年起成為正式CEO，帶領蘋果輝煌的iPod、iPhone、iPad時代的到來。從2003年10月起，賈伯斯與胰腺神經內分泌腫瘤奮戰了8年，\\\n",
    "最終於2011年8月辭任執行長一職，在他第3次病假期間，賈伯斯當選為蘋果公司的董事長。'\n",
    "\n",
    "\n",
    "question = ['NeXT公司是誰創造的','NeXT公司是在哪年成立','誰決議買下NeXT公司','誰成立了皮克斯'\n",
    "            ,'誰是《玩具總動員》的執行製片人','皮克斯動畫在哪年被華特迪士尼公司收購']\n",
    "\n",
    "\n",
    "for q in question:\n",
    "    print(q + ':  '+ drcd_model.inference(content,q))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNVM3uYt3pO9lYSGqAyojSw",
   "collapsed_sections": [
    "1Rru4MXtiSQ0"
   ],
   "include_colab_link": true,
   "name": "chinese_mrc_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
