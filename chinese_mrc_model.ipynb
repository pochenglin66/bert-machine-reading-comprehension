{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Cn-gQTGhC7z"
   },
   "source": [
    "# BERT fine tune DRCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uubPXZfugyLD",
    "outputId": "a13176bc-25cd-4e8b-c079-ee9e7b8ad9d2"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from transformers import *\n",
    "import pandas as pd\n",
    "import ast\n",
    "import copy\n",
    "import os\n",
    "import json\n",
    "from time import strftime,gmtime\n",
    "from opencc import OpenCC\n",
    "import pyprind\n",
    "from sklearn.utils import shuffle\n",
    "import re\n",
    "from zhon.hanzi import non_stops, stops\n",
    "import numpy as np\n",
    "import random\n",
    "import argparse\n",
    "import time\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class DRCDRawData():\n",
    "    def __init__(self, train_path=None , test_path=None ,dev_path=None):\n",
    "        if train_path != None:\n",
    "            self.train = self.load_data(train_path)\n",
    "        if test_path != None:\n",
    "            self.test = self.load_data(test_path)\n",
    "        if dev_path != None:\n",
    "            self.dev = self.load_data(dev_path)\n",
    "    def load_data(self,path):\n",
    "        dataset = json.load(open(path, encoding='utf-8'))\n",
    "        result = []\n",
    "        for i in range(len(dataset['data'])):\n",
    "            for j in dataset['data'][i]['paragraphs']:\n",
    "                context = j['context']\n",
    "                for qa in j['qas']:\n",
    "                    question = qa['question']\n",
    "                    if qa['answers']:\n",
    "                        result.append([context,question,qa['answers'][0]['text']])                     \n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7P7DpSVMcy7Y"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kFAFURdNcP77"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class DRCD(Dataset):\n",
    "    def __init__(self, data, model_type, device, language):\n",
    "        self.data = data\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model_type)\n",
    "        self.device = device\n",
    "        self.cc = OpenCC('t2s') # tw->china\n",
    "        self.language = language\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        paragraph, question, ans = self.data[idx][0], self.data[idx][1], self.data[idx][2] \n",
    "        \n",
    "        if self.language == 'china':\n",
    "            paragraph, question, ans = self.cc.convert(paragraph), self.cc.convert(question), self.cc.convert(ans)\n",
    "        \n",
    "        # Tokenize and prepare for the model a sequence or a pair of sequences. \n",
    "        # so unlike 'encode' just encode to ids, encode_plus return not only ids \n",
    "        # but token_type_ids, attention_mask also\n",
    "        token_tensor = self.tokenizer.encode_plus(question, paragraph, max_length=512, \n",
    "                                                  truncation=True, pad_to_max_length=True)\n",
    "        \n",
    "        ans_encode = self.tokenizer.encode(ans)\n",
    "        s_tensor, e_tensor = self.find_ans_index(token_tensor, ans_encode)\n",
    "\n",
    "        return {'input_ids': torch.tensor(token_tensor['input_ids']).to(self.device),\n",
    "                'token_type_ids': torch.tensor(token_tensor['token_type_ids']).to(self.device),\n",
    "                'attention_mask': torch.tensor(token_tensor['attention_mask']).to(self.device),\n",
    "                's_tensor': s_tensor.to(self.device),\n",
    "                'e_tensor': e_tensor.to(self.device)}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def find_ans_index(self, token_tensor, ans_encode):\n",
    "        s_idx, e_idx = [0] * 512, [0] * 512\n",
    "\n",
    "        # answer's token (removing [CLS] and [SEP] by [1:-1])\n",
    "        s_tok = ans_encode[1:-1]\n",
    "        \n",
    "        # find the idx of paragraph startwith ans's first token \n",
    "        s_list = [i for i, x in enumerate(token_tensor['input_ids']) if x == s_tok[0]]\n",
    "      \n",
    "        for s_pos in s_list:\n",
    "            e_pos = s_pos + len(s_tok)\n",
    "            if e_pos > 511:\n",
    "                continue\n",
    "            if token_tensor['input_ids'][s_pos:e_pos] == s_tok:\n",
    "                s_idx[s_pos] = 1\n",
    "                e_idx[e_pos-1] = 1\n",
    "                break\n",
    "        return  torch.Tensor(s_idx), torch.Tensor(e_idx)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Z-zDS64xoOO"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForReadingComprehension(nn.Module):\n",
    "    def __init__(self, model_type):\n",
    "        super(BertForReadingComprehension, self).__init__()\n",
    "\n",
    "        config = BertConfig.from_pretrained(model_type, output_hidden_states=True)\n",
    "        self.bert_model = BertModel.from_pretrained(model_type, config=config)\n",
    "        \n",
    "        self.s_decoder = nn.Sequential(nn.Linear(config.hidden_size, 1)) \n",
    "        self.e_decoder = nn.Sequential(nn.Linear(config.hidden_size, 1))\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None): \n",
    "        hidden = self.bert_model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)[0]\n",
    "        \n",
    "        s = self.s_decoder(hidden).squeeze()\n",
    "        e = self.e_decoder(hidden).squeeze()\n",
    "        \n",
    "        # mask question part, because ans only appear in paragraph.\n",
    "        mask = token_type_ids.clone().float().to(hidden.device).detach()\n",
    "        mask[mask != 1] = float('-inf')\n",
    "\n",
    "        return s + mask, e + mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2tNzN6c-xZ_A"
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-YduImGhxb6q"
   },
   "outputs": [],
   "source": [
    "def test(model, data, args, tp):\n",
    "    if tp == 'test':\n",
    "        dataset = DRCD(data.test, args.model_type, args.device, args.language)\n",
    "        print(f'Testing...{len(dataset)}')\n",
    "    elif tp == 'dev':   \n",
    "        dataset = DRCD(data.dev, args.model_type, args.device, args.language)\n",
    "        print(f'Dev...{len(dataset)}')\n",
    "    loader = DataLoader(dataset, batch_size=args.batch_size, shuffle=True)\n",
    "    model.eval()\n",
    "    loss,i = 0,0\n",
    "    print(loss,i)\n",
    "    criterion = nn.BCELoss()\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            i = i+1\n",
    "            inp_ids, tok_id, att_m, slabel, elabel = batch['input_ids'], batch['token_type_ids'], batch['attention_mask'], batch['s_tensor'], batch['e_tensor']\n",
    "            s, e = model(input_ids=inp_ids,attention_mask=att_m,token_type_ids=tok_id)\n",
    "            #print(f's {s} \\n e {e} \\n sl {torch.softmax(s,dim=-1)} \\n el {torch.softmax(e,dim=-1)} \\n ')\n",
    "            #print(f'SL {slabel} \\n EL {elabel}')\n",
    "            batch_loss = (criterion(torch.softmax(s,dim=-1),slabel) + criterion(torch.softmax(e,dim=-1),elabel)) / 2\n",
    "            loss += batch_loss\n",
    "            \n",
    "        print(f'Result: LOSS: {loss} AVG: {loss/i} ')\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EGbz1SUhxcb2"
   },
   "outputs": [],
   "source": [
    "def train(data, args):\n",
    "    dataset = DRCD(data.train, args.model_type, args.device, args.language)\n",
    "    trainLoader = DataLoader(dataset, batch_size=args.batch_size, shuffle=True)\n",
    "    model = BertForReadingComprehension(args.model_type).to(args.device)\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = AdamW(parameters, lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "    criterion = nn.BCELoss()\n",
    "    model.train()\n",
    "    min_loss = 100000\n",
    "    for ei in range(args.epoch):\n",
    "        model.train()\n",
    "        epoch_loss,i,check_loss = 0,0,0\n",
    "        for batch in trainLoader:\n",
    "            i+=1\n",
    "            inp_ids, tok_id, att_m , slabel, elabel = batch['input_ids'], batch['token_type_ids'], batch['attention_mask'],batch['s_tensor'],batch['e_tensor']\n",
    "            \n",
    "            s, e = model(input_ids=inp_ids, \n",
    "                         attention_mask=att_m,\n",
    "                         token_type_ids=tok_id)\n",
    "            \n",
    "            #print(f's {s} \\n e {e} \\n sl {torch.softmax(s,dim=-1)} \\n el {torch.softmax(e,dim=-1)} \\n ')\n",
    "            #print(f'SL {slabel} \\n EL {elabel}')\n",
    "            \n",
    "            batch_loss = (criterion(torch.softmax(s,dim=-1),slabel) + criterion(torch.softmax(e,dim=-1),elabel)) / 2\n",
    "            epoch_loss += batch_loss\n",
    "            check_loss += batch_loss\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            if i % 1000==0:\n",
    "                print(f'1000 batch LOSS {check_loss}')\n",
    "                check_loss = 0\n",
    "        dev_loss = test(model, data, args, 'dev') \n",
    "        if dev_loss < min_loss:\n",
    "            min_loss = dev_loss\n",
    "            best_model = copy.deepcopy(model.state_dict()) \n",
    "            model_name = 'BertForReadingComprehension'+'_'+(datetime.now()).strftime(\"%m%d\")+'.pt' \n",
    "            torch.save(best_model, f'model/{model_name}')\n",
    "            print(f'Model name is {model_name}')\n",
    "            print('min_loss is', str(min_loss))\n",
    "        print(f'===Epoches: {ei} Loss {epoch_loss}===')   \n",
    "        \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "llu-ld14gYdA"
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "x8P9_YXsgaCT",
    "outputId": "b0d26f7b-3f4a-4300-f0a8-0feb6d9e9874"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Quadro P2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Namespace(batch_size=2, device=device(type='cuda', index=0), epoch=5, language='tw', learning_rate=1e-05, model_type='hfl/chinese-roberta-wwm-ext', weight_decay=0.001)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "parser = argparse.ArgumentParser([])\n",
    "parser.add_argument('--batch-size', default=32 , type=int)\n",
    "parser.add_argument('--epoch', default=5, type=int)\n",
    "parser.add_argument('--learning-rate', default=1e-5, type=float)    \n",
    "parser.add_argument('--weight-decay', default=0.001, type=float)\n",
    "parser.add_argument('--model-type', default='hfl/chinese-roberta-wwm-ext' , type=str)  #model_type = 'hfl/chinese-bert-wwm'  'hfl/chinese-roberta-wwm-ext'  'hfl/chinese-roberta-wwm-ext-large'\n",
    "parser.add_argument('--device', default=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu'), type=int)\n",
    "parser.add_argument('--language', default='tw', type=str)\n",
    "args = parser.parse_args([])\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ac4TkXWchw4L"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2010年引進的廣州快速公交運輸系統，屬世界第二大快速公交系統，日常載客量可達100萬人次，高峰時期每小時單向客流高達26900人次，僅次於波哥大的快速交通系統，平均每10秒鐘就有一輛巴士，每輛巴士單向行駛350小時。包括橋樑在內的站台是世界最長的州快速公交運輸系統站台，長達260米。目前廣州市區的計程車和公共汽車主要使用液化石油氣作燃料，部分公共汽車更使用油電、氣電混合動力技術。2012年底開始投放液化天然氣燃料的公共汽車，2014年6月開始投放液化天然氣插電式混合動力公共汽車，以取代液化石油氣公共汽車。2007年1月16日，廣州市政府全面禁止在市區內駕駛摩托車。違反禁令的機動車將會予以沒收。廣州市交通局聲稱禁令的施行，使得交通擁擠問題和車禍大幅減少。廣州白雲國際機場位於白雲區與花都區交界，2004年8月5日正式投入運營，屬中國交通情況第二繁忙的機場。該機場取代了原先位於市中心的無法滿足日益增長航空需求的舊機場。目前機場有三條飛機跑道，成為國內第三個擁有三跑道的民航機場。比鄰近的香港國際機場第三跑道預計的2023年落成早8年。',\n",
       " '廣州的快速公交運輸系統每多久就會有一輛巴士？',\n",
       " '10秒鐘']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = DRCDRawData(train_path='./dataset/DRCD_train.json', test_path='./dataset/DRCD_test.json', dev_path='./dataset/DRCD_dev.json')\n",
    "data.train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "id": "bEyDq_PC1i82",
    "outputId": "6e6dafc9-e7b0-408f-8b80-337644122cc1"
   },
   "outputs": [],
   "source": [
    "mode = 'train'\n",
    "\n",
    "if mode == 'train': \n",
    "    train(data, args)\n",
    "elif mode == 'test' or mode == 'dev':\n",
    "    model_name = 'bertDRCD_0808_1213.pt'\n",
    "    test_model = BertForReadingComprehension(args.model_type).to(args.device)\n",
    "    test_model.load_state_dict(torch.load(f'model/{model_name}'))\n",
    "    test(test_model, data, args, mode)\n",
    "\n",
    "#22.53021812438965\n",
    "#22.579822540283203\n",
    "# Result: LOSS: 3.2912609577178955 AVG: 0.003765744622796774 \n",
    "# Result: LOSS: 3.526034116744995 AVG: 0.004002308938652277 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N7n5HS36ex16"
   },
   "source": [
    "# Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SVfxojHYfKJT"
   },
   "outputs": [],
   "source": [
    "class InferenceModel():\n",
    "    def __init__(self, model_path, model_type, language): \n",
    "\n",
    "        self.device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "        config = BertConfig.from_pretrained(model_type,output_hidden_states=True)\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model_type)\n",
    "        self.model = BertForReadingComprehension(model_type).to(self.device)\n",
    "        self.model.load_state_dict(torch.load(model_path)) \n",
    "        self.language = language\n",
    "\n",
    "        self.c2tw = OpenCC('s2t') # china to tw\n",
    "        self.tw2c = OpenCC('t2s') # tw to china\n",
    "\n",
    "    def inference(self, content, question):\n",
    "        \n",
    "        content, question = self.clean_str(content, question)\n",
    "        \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            token_tensor = self.tokenizer.encode_plus(str(question), str(content), max_length=512, \n",
    "                                                      truncation=True, pad_to_max_length=True)\n",
    "            token = torch.tensor(token_tensor['input_ids']).unsqueeze(0).to(self.device)\n",
    "            segment = torch.tensor( token_tensor['token_type_ids']).unsqueeze(0).to(self.device)\n",
    "            mask = torch.tensor( token_tensor['attention_mask'] ).unsqueeze(0).to(self.device)\n",
    "            answer_start, answer_end = self.model(input_ids=token,attention_mask=mask,token_type_ids=segment) \n",
    "      \n",
    "            tokens = self.tokenizer.convert_ids_to_tokens(token.squeeze())\n",
    "            answer_start = answer_start.argmax(1)\n",
    "            answer_end = answer_end.argmax(1)\n",
    "            #print(answer_start,answer_end)\n",
    "            if answer_start > answer_end :\n",
    "                return 'Invalid span.'\n",
    "            \n",
    "            #print(answer_start,answer_end)\n",
    "            answer = ''.join(tokens[answer_start:answer_end+1])\n",
    "            if self.language == 'tw':\n",
    "                answer = self.c2tw.convert(answer)\n",
    "            \n",
    "            \n",
    "        \n",
    "        return answer\n",
    "    \n",
    "    def clean_str(self, content, question):\n",
    "        content = content.replace(' ','')\n",
    "        question = question.replace(' ','')\n",
    "        if self.language == 'china':\n",
    "            content = self.tw2c.convert(content)\n",
    "            question = self.tw2c.convert(question)\n",
    "\n",
    "        return content, question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "76m8dUy1ew9t",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "model_name = 'bertDRCD_1023_1619.pkl'\n",
    "drcd_model = InferenceModel(f'model/{model_name}','hfl/chinese-roberta-wwm-ext','tw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pocheng.lin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "蒂埃里·亨利是誰:  前法國足球運動員\n",
      "蒂埃里·亨利為法國隊出場幾次:  123次\n",
      "亨利曾在國際比賽中上演過帽子戲法嗎?:  從未\n",
      "蒂埃里·亨利是誰在哪年歐洲國家盃外圍賽中曾單場上演大四喜?:  2004年\n",
      "亨利在熱身賽中共打進多少球?:  16球\n"
     ]
    }
   ],
   "source": [
    "paragraph = \\\n",
    "'蒂埃里·亨利是前法國足球運動員。在他職業生涯參加的國際賽事中，他為法國隊出場123次，\\\n",
    "打進51球。他的首個國際比賽進球是在1998年世界盃對陣南非的比賽中。截至2015年10月，他是法國隊的頭號射手\\\n",
    "。2007年10月，他在對陣立陶宛的比賽中打進兩球，打破了米歇爾·普拉蒂尼42球的法國隊進球紀錄。亨利於2010年7月正式退役\\\n",
    "。亨利在2009年10月對奧地利的比賽中打進了個人國家隊第51粒進球，這也是他的最後一粒進球\\\n",
    "。亨利從未在國際比賽中上演過帽子戲法，儘管他曾7次在單場比賽梅開二度。\\\n",
    "他在對陣馬爾他的比賽中進球最多，在2004年歐洲國家盃外圍賽中曾單場上演大四喜。\\\n",
    "亨利一半以上的進球來自於主場比賽，他的51個進球中有31個是在法國本土打進，\\\n",
    "其中有20個在法蘭西體育場。亨利在熱身賽中共打進16球。在2003年國際足總洲際國家盃上\\\n",
    "，亨利打進四球並榮膺最佳射手，他也因此被評為「賽事最傑出球員」。\\\n",
    "亨利在歐洲國家盃外圍賽中打入12球，其中在2004年歐洲杯外圍賽打進6球，他最終排在射手榜第三位。'\n",
    "\n",
    "question = ['蒂埃里·亨利是誰','蒂埃里·亨利為法國隊出場幾次','亨利曾在國際比賽中上演過帽子戲法嗎?',\n",
    "            '蒂埃里·亨利是誰在哪年歐洲國家盃外圍賽中曾單場上演大四喜?','亨利在熱身賽中共打進多少球?']\n",
    "\n",
    "for q in question:\n",
    "    print(q + ':  '+ drcd_model.inference(paragraph,q))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNVM3uYt3pO9lYSGqAyojSw",
   "collapsed_sections": [
    "1Rru4MXtiSQ0"
   ],
   "include_colab_link": true,
   "name": "chinese_mrc_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
